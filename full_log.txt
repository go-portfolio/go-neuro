=== Training Start ===
Epoch 0 — loss=0.737667
Epoch 200 — loss=0.327834
Epoch 400 — loss=0.327834
Epoch 600 — loss=0.327834
Ранняя остановка на эпохе 600 (нет улучшений 500 эпох)
Training done!


=== Sample 0: Input=[0 0] ===

--- Layer 0 (Input Layer, neurons=2) ---
Layer 0 outputs (A): [0 0]

--- Layer 1 (neurons=10) ---
Neuron 0: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 1: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 2: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 3: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 4: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 5: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 6: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 7: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 8: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 9: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Layer 1 outputs (A): [0 0 0 0 0 0 0 0 0 0]

--- Layer 2 (neurons=3) ---
Neuron 0: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.5127, Z=0.5127 → A=0.5127
Neuron 1: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.2541, Z=0.2541 → A=0.2541
Neuron 2: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.7668, Z=0.7668 → A=0.7668
Layer 2 outputs (A): [0.5127458120903132 0.2540616654527798 0.7668074775430929]

Network Output:
 Output neuron 0: 0.5127 (rounded 1), Target: 0
 Output neuron 1: 0.2541 (rounded 0), Target: 0
 Output neuron 2: 0.7668 (rounded 1), Target: 0

=== Sample 1: Input=[0 1] ===

--- Layer 0 (Input Layer, neurons=2) ---
Layer 0 outputs (A): [0 1]

--- Layer 1 (neurons=10) ---
Neuron 0: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 1: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 2: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 3: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 4: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 5: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 6: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 7: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 8: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 9: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Layer 1 outputs (A): [0 0 0 0 0 0 0 0 0 0]

--- Layer 2 (neurons=3) ---
Neuron 0: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.5127, Z=0.5127 → A=0.5127
Neuron 1: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.2541, Z=0.2541 → A=0.2541
Neuron 2: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.7668, Z=0.7668 → A=0.7668
Layer 2 outputs (A): [0.5127458120903132 0.2540616654527798 0.7668074775430929]

Network Output:
 Output neuron 0: 0.5127 (rounded 1), Target: 1
 Output neuron 1: 0.2541 (rounded 0), Target: 0
 Output neuron 2: 0.7668 (rounded 1), Target: 1

=== Sample 2: Input=[1 0] ===

--- Layer 0 (Input Layer, neurons=2) ---
Layer 0 outputs (A): [1 0]

--- Layer 1 (neurons=10) ---
Neuron 0: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 1: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 2: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 3: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 4: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 5: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 6: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 7: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 8: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 9: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Layer 1 outputs (A): [0 0 0 0 0 0 0 0 0 0]

--- Layer 2 (neurons=3) ---
Neuron 0: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.5127, Z=0.5127 → A=0.5127
Neuron 1: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.2541, Z=0.2541 → A=0.2541
Neuron 2: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.7668, Z=0.7668 → A=0.7668
Layer 2 outputs (A): [0.5127458120903132 0.2540616654527798 0.7668074775430929]

Network Output:
 Output neuron 0: 0.5127 (rounded 1), Target: 1
 Output neuron 1: 0.2541 (rounded 0), Target: 0
 Output neuron 2: 0.7668 (rounded 1), Target: 1

=== Sample 3: Input=[1 1] ===

--- Layer 0 (Input Layer, neurons=2) ---
Layer 0 outputs (A): [1 1]

--- Layer 1 (neurons=10) ---
Neuron 0: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 1: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 2: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 3: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 4: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 5: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 6: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 7: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 8: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Neuron 9: Weights=[0 0], Bias=0.0000, Z=0.0000 → A=0.0000
Layer 1 outputs (A): [0 0 0 0 0 0 0 0 0 0]

--- Layer 2 (neurons=3) ---
Neuron 0: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.5127, Z=0.5127 → A=0.5127
Neuron 1: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.2541, Z=0.2541 → A=0.2541
Neuron 2: Weights=[0 0 0 0 0 0 0 0 0 0], Bias=0.7668, Z=0.7668 → A=0.7668
Layer 2 outputs (A): [0.5127458120903132 0.2540616654527798 0.7668074775430929]

Network Output:
 Output neuron 0: 0.5127 (rounded 1), Target: 0
 Output neuron 1: 0.2541 (rounded 0), Target: 1
 Output neuron 2: 0.7668 (rounded 1), Target: 1

=== Predictions for OR ===
Input: [0 0] → Output: 0.7668 (rounded 1), Target: 0
Input: [0 1] → Output: 0.7668 (rounded 1), Target: 1
Input: [1 0] → Output: 0.7668 (rounded 1), Target: 1
Input: [1 1] → Output: 0.7668 (rounded 1), Target: 1

=== Predictions for XOR ===
Input: [0 0] → Output: 0.5127 (rounded 1), Target: 0
Input: [0 1] → Output: 0.5127 (rounded 1), Target: 1
Input: [1 0] → Output: 0.5127 (rounded 1), Target: 1
Input: [1 1] → Output: 0.5127 (rounded 1), Target: 0

=== Predictions for AND ===
Input: [0 0] → Output: 0.2541 (rounded 0), Target: 0
Input: [0 1] → Output: 0.2541 (rounded 0), Target: 0
Input: [1 0] → Output: 0.2541 (rounded 0), Target: 0
Input: [1 1] → Output: 0.2541 (rounded 0), Target: 1
