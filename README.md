–í–æ—Ç **README.md** –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–º –∏ —á–∏—Å—Ç–æ–º **Markdown**
(–Ω–∏–∫–∞–∫–æ–≥–æ HTML, —Ç–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π markdown-—Å–∏–Ω—Ç–∞–∫—Å–∏—Å).

–°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–∞–∫ –µ—Å—Ç—å:

---

```markdown
# Go-Neuro ‚Äî –ø—Ä–æ—Å—Ç–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å –Ω–∞ Go

Go-Neuro ‚Äî —ç—Ç–æ —É—á–µ–±–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ (MLP) –Ω–∞ —è–∑—ã–∫–µ Go **—Å –Ω—É–ª—è**, –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.  
–ü—Ä–æ–µ–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç, –∫–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω—ã —Å–ª–æ–∏, –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, –æ–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ (backpropagation)  
–∏ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ–±—É—á–µ–Ω–∏—è.

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞



project/
‚îÇ   main.go
‚îÇ   README.md
‚îÇ
‚îî‚îÄ‚îÄ nn/
‚îú‚îÄ‚îÄ activations.go
‚îú‚îÄ‚îÄ layer.go
‚îú‚îÄ‚îÄ network.go
‚îÇ
‚îú‚îÄ‚îÄ trainers/
‚îÇ     ‚îú‚îÄ‚îÄ sgd.go
‚îÇ     ‚îî‚îÄ‚îÄ adam.go
‚îÇ
‚îî‚îÄ‚îÄ dataset/
‚îú‚îÄ‚îÄ dataset.go
‚îú‚îÄ‚îÄ xor.go
‚îú‚îÄ‚îÄ and.go
‚îî‚îÄ‚îÄ or.go



---

## üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–µ–∫—Ç–∞

```bash
go run ./...
````

---

## üõ† –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

```go
ds := dataset.MustGet("xor")

net := nn.NewNetwork([]int{2, 2, 1})
trainer := &trainers.SGDTrainer{LearningRate: 0.5}

net.Fit(trainer, ds.Samples, ds.Targets, 20000)
```

–ü—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:

```
Epoch 0, loss=0.250000
Epoch 1000, loss=0.015124
Epoch 20000, loss=0.000012

Input: [0 1] ‚Üí 0.9821 (rounded 1), Target: [1]
```

---

## üì¶ –î–∞—Ç–∞—Å–µ—Ç—ã

–ö–∞–∂–¥—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø–∞–∫–µ—Ç–∞:

```go
func init() {
    Register("xor", DataSet{
        Samples: [][]float64{
            {0, 0}, {0, 1}, {1, 0}, {1, 1},
        },
        Targets: [][]float64{
            {0}, {1}, {1}, {0},
        },
    })
}
```

–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞:

```go
ds := dataset.MustGet("xor")
```

---

## üèãÔ∏è –ú–µ—Ç–æ–¥—ã –æ–±—É—á–µ–Ω–∏—è

–ö–∞–∂–¥—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–µ–∞–ª–∏–∑—É–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:

```go
type Trainer interface {
    Update(net *Network, samples, targets [][]float64, epochs int)
}
```

### –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–µ—Ä—ã

| –ò–º—è           | –¢–∏–ø               | –û–ø–∏—Å–∞–Ω–∏–µ                                 |
| ------------- | ----------------- | ---------------------------------------- |
| `SGDTrainer`  | –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ | –ü–æ–ª–Ω—ã–π backpropagation                   |
| `AdamTrainer` | Adam              | –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω, –ª–µ–≥–∫–æ —Ä–∞—Å—à–∏—Ä—è–µ—Ç—Å—è |

---

## üîß –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –æ–±—É—á–µ–Ω–∏—è

1. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª –≤ `nn/trainers/`:

```
nn/trainers/mytrainer.go
```

2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:

```go
type MyTrainer struct {
    LearningRate float64
}

func (t *MyTrainer) Update(net *nn.Network, samples, targets [][]float64, epochs int) {
    // –ª–æ–≥–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
}
```

3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:

```go
trainer := &trainers.MyTrainer{LearningRate: 0.01}
net.Fit(trainer, samples, targets, 10000)
```

---

## ‚ú® –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

1. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª:

```
nn/dataset/mydata.go
```

2. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç:

```go
func init() {
    Register("mydata", DataSet{
        Samples: [][]float64{...},
        Targets: [][]float64{...},
    })
}
```

3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:

```go
ds := dataset.MustGet("mydata")
```

---

## üìú –õ–∏—Ü–µ–Ω–∑–∏—è

–°–≤–æ–±–æ–¥–Ω–æ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, –∏–∑—É—á–µ–Ω–∏—è –∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏.

